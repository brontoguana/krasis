================================================================
Krasis Benchmark — 2026-02-17 17:20:09
================================================================
Model:            Qwen3-Coder-Next
Architecture:     qwen3_next, 48 layers, 512 experts, top-10, 12 GQA + 36 linear
PP Partition:     [48] (1 GPUs)
NOTE:             Launched with --num-gpus 3 but EHCS removed in 681014e, so HCS only uses GPU 0

Hardware:
  CPU:            AMD EPYC 7742 64-Core Processor (64 cores)
  RAM:            995 GB total, 77.7 GB used by process
  GPU 0:          NVIDIA RTX 2000 Ada Generation (16380 MB), 13023 MB allocated
  GPU 1:          NVIDIA RTX 2000 Ada Generation (16380 MB), 0 MB allocated
  GPU 2:          NVIDIA RTX 2000 Ada Generation (16380 MB), 0 MB allocated

Quantization:
  GPU experts:    INT4 (Marlin)
  CPU experts:    INT4
  Attention:      INT8
  Shared expert:  INT8
  Dense MLP:      INT8
  LM head:        INT8
  KV cache:       FP8 E4M3

Strategy:
  Expert divisor: -3 (hot_cached_static)
  Prefill threshold: 1
  Mode:           gpu_decode (hot_cached_static)
  HCS experts:    5074 on cuda:0 only (8230 MB), ~70% cold per layer

Prefill (10000 tokens, 3 runs):
  Run 1:  535.0 tok/s, TTFT=18.69s
  Run 2:  536.5 tok/s, TTFT=18.64s
  Run 3:  536.0 tok/s, TTFT=18.66s
  Average: 535.8 tok/s, TTFT=18.66s

Decode (64 tokens, 3 runs):
  Run 1:  7.51 tok/s (133.2ms/tok)
  Run 2:  7.55 tok/s (132.4ms/tok)
  Run 3:  7.55 tok/s (132.4ms/tok)
  Average: 7.54 tok/s (132.7ms/tok)

Verification:
  Prefill prompt: user
Explain distributed consensus algorithms... [63136 chars total]
  Decode prompt:  Write a poem about recursion in programming.
  Generated output (64 tokens):
    **The Ladder of Self-Call**

    A function stands, both firm and tall,
    With purpose clear, and mind in thrall.
    It checks a base—a simple test—
    If *n* is zero, rest be blessed.

    > *"Return one,"* it softly says,

================================================================
